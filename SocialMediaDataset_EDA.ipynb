{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226606dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd32450a",
   "metadata": {},
   "source": [
    "# 1. CED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "da0a1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "base_path = r'E:\\social media datasets\\CED\\Chinese_Rumor_Dataset-master\\CED_Dataset'  # Replace with actual base path\n",
    "original_path = os.path.join(base_path, 'original-microblog')\n",
    "repost_paths = {\n",
    "    'rumor': os.path.join(base_path, 'rumor-repost'),\n",
    "    'nonrumor': os.path.join(base_path, 'non-rumor-repost')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "98d77761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_ced_original_posts(original_path, repost_paths):\n",
    "    original_records = []\n",
    "\n",
    "    for filename in os.listdir(original_path):\n",
    "        if not filename.endswith('.json'):\n",
    "            continue\n",
    "\n",
    "        microblog_id = filename.replace('.json', '')\n",
    "        original_file = os.path.join(original_path, filename)\n",
    "\n",
    "        try:\n",
    "            data = load_json(original_file)\n",
    "\n",
    "            user = data.get(\"user\", {})\n",
    "            if not isinstance(user, dict):\n",
    "                user = {}\n",
    "\n",
    "            label = None\n",
    "            for lbl, path in repost_paths.items():\n",
    "                if os.path.exists(os.path.join(path, filename)):\n",
    "                    label = lbl\n",
    "                    break\n",
    "            if label is None:\n",
    "                continue\n",
    "\n",
    "            original_records.append({\n",
    "            \"id\": microblog_id,\n",
    "            \"text\": data.get(\"text\", \"\"),\n",
    "            \"time\": data.get(\"time\", None),\n",
    "            \"followers\": user.get(\"followers\", None),\n",
    "            \"friends\": user.get(\"friends\", None),\n",
    "            \"verified\": user.get(\"verified\", False),\n",
    "            \"reposts\": data.get(\"reposts\", 0),\n",
    "            \"likes\": data.get(\"likes\", 0),\n",
    "            \"label\": label,\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(original_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6114734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>followers</th>\n",
       "      <th>friends</th>\n",
       "      <th>verified</th>\n",
       "      <th>reposts</th>\n",
       "      <th>likes</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_yBmepBtUB_2279086572</td>\n",
       "      <td>人间惨剧：今天下午约14点，宁波妇儿医院，一妇女携带一婴儿在住院楼跳楼，后抢救无效死亡。具体...</td>\n",
       "      <td>1347334462</td>\n",
       "      <td>227833.0</td>\n",
       "      <td>907.0</td>\n",
       "      <td>False</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000_yFDQ0ffqy_2082357197</td>\n",
       "      <td>再去武大，已无牌坊！非要拆掉？@章立凡 @袁裕来律师 @老徐时评 @徐昕 @杨锦麟 @左小祖...</td>\n",
       "      <td>1349768694</td>\n",
       "      <td>59624.0</td>\n",
       "      <td>1923.0</td>\n",
       "      <td>False</td>\n",
       "      <td>395</td>\n",
       "      <td>0</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002_zne7v6NMq_2464670392</td>\n",
       "      <td>中国最美丽的乡村\"江西婺源\"一\"教师打死学生\" 昨晚，在被誉为中国最美丽的乡村江西省婺源县清...</td>\n",
       "      <td>1363146924</td>\n",
       "      <td>66.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>False</td>\n",
       "      <td>685</td>\n",
       "      <td>0</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003_AcDAZonRf_1603208240</td>\n",
       "      <td>忍者QS：江苏省东海县女镇党委书记徐艳，因不愿陪县委书记关永健上床，竟然被警察毒打致子宫破裂...</td>\n",
       "      <td>1380971862</td>\n",
       "      <td>8358.0</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>False</td>\n",
       "      <td>120</td>\n",
       "      <td>6</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004_zvUcLCeTm_3186420187</td>\n",
       "      <td>《北大猛男，持刀刺官！！！》“可歌可泣”的是王同学投案自首之后冷冷说了一句话是 “我并不后悔...</td>\n",
       "      <td>1368078370</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>False</td>\n",
       "      <td>532</td>\n",
       "      <td>11</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  \\\n",
       "0     0_yBmepBtUB_2279086572   \n",
       "1  1000_yFDQ0ffqy_2082357197   \n",
       "2  1002_zne7v6NMq_2464670392   \n",
       "3  1003_AcDAZonRf_1603208240   \n",
       "4  1004_zvUcLCeTm_3186420187   \n",
       "\n",
       "                                                text        time  followers  \\\n",
       "0  人间惨剧：今天下午约14点，宁波妇儿医院，一妇女携带一婴儿在住院楼跳楼，后抢救无效死亡。具体...  1347334462   227833.0   \n",
       "1  再去武大，已无牌坊！非要拆掉？@章立凡 @袁裕来律师 @老徐时评 @徐昕 @杨锦麟 @左小祖...  1349768694    59624.0   \n",
       "2  中国最美丽的乡村\"江西婺源\"一\"教师打死学生\" 昨晚，在被誉为中国最美丽的乡村江西省婺源县清...  1363146924       66.0   \n",
       "3  忍者QS：江苏省东海县女镇党委书记徐艳，因不愿陪县委书记关永健上床，竟然被警察毒打致子宫破裂...  1380971862     8358.0   \n",
       "4  《北大猛男，持刀刺官！！！》“可歌可泣”的是王同学投案自首之后冷冷说了一句话是 “我并不后悔...  1368078370     1096.0   \n",
       "\n",
       "   friends  verified  reposts  likes  label  \n",
       "0    907.0     False      225      0  rumor  \n",
       "1   1923.0     False      395      0  rumor  \n",
       "2     82.0     False      685      0  rumor  \n",
       "3   1474.0     False      120      6  rumor  \n",
       "4   1118.0     False      532     11  rumor  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ced_original = load_ced_original_posts(original_path, repost_paths)\n",
    "ced_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7e13e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rumor', 'nonrumor'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ced_original.label.unique() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0ad8cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "nonrumor    1849\n",
       "rumor       1538\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ced_original.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "865315e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(ced_original['time'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcbed811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ced_repost_posts(repost_paths, original_path):\n",
    "    repost_records = []\n",
    "\n",
    "    for filename in os.listdir(original_path):\n",
    "        if not filename.endswith('.json'):\n",
    "            continue\n",
    "\n",
    "        microblog_id = filename.replace('.json', '')\n",
    "        repost_file = None\n",
    "        label = None\n",
    "\n",
    "        for lbl, path in repost_paths.items():\n",
    "            candidate = os.path.join(path, filename)\n",
    "            if os.path.exists(candidate):\n",
    "                repost_file = candidate\n",
    "                label = lbl\n",
    "                break\n",
    "\n",
    "        if repost_file is None:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            repost_data = load_json(repost_file)\n",
    "            for repost in repost_data:\n",
    "                repost_records.append({\n",
    "                    \"id\": microblog_id,\n",
    "                    \"text\": repost.get(\"text\", \"\"),\n",
    "\n",
    "                    \"label\": label\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing repost file {filename}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(repost_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a90240a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_yBmepBtUB_2279086572</td>\n",
       "      <td></td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_yBmepBtUB_2279086572</td>\n",
       "      <td></td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_yBmepBtUB_2279086572</td>\n",
       "      <td>现实残酷加产后抑郁。。。以前听教授讲过，很多产科医生对抑郁症认识不足。</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_yBmepBtUB_2279086572</td>\n",
       "      <td>不实报道和不好报道，不能仅用逻辑判断。未经证实的报道，不转发，不评论，不判断，才是所谓公知们...</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_yBmepBtUB_2279086572</td>\n",
       "      <td>难道这样的悲剧，号称我们的父母官没有责任？</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                               text  \\\n",
       "0  0_yBmepBtUB_2279086572                                                      \n",
       "1  0_yBmepBtUB_2279086572                                                      \n",
       "2  0_yBmepBtUB_2279086572                现实残酷加产后抑郁。。。以前听教授讲过，很多产科医生对抑郁症认识不足。   \n",
       "3  0_yBmepBtUB_2279086572  不实报道和不好报道，不能仅用逻辑判断。未经证实的报道，不转发，不评论，不判断，才是所谓公知们...   \n",
       "4  0_yBmepBtUB_2279086572                              难道这样的悲剧，号称我们的父母官没有责任？   \n",
       "\n",
       "   label  \n",
       "0  rumor  \n",
       "1  rumor  \n",
       "2  rumor  \n",
       "3  rumor  \n",
       "4  rumor  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ced_reposts = load_ced_repost_posts(repost_paths, original_path)\n",
    "ced_reposts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72cd6e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "nonrumor    791563\n",
       "rumor       483617\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ced_reposts.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c523aa",
   "metadata": {},
   "source": [
    "# 2. FbMultiLingMisinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "350179b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>counter</th>\n",
       "      <th>dataset</th>\n",
       "      <th>timestamp_first_tweet</th>\n",
       "      <th>timestamp_last_tweet</th>\n",
       "      <th>date_first_tweet</th>\n",
       "      <th>date_last_tweet</th>\n",
       "      <th>days_betweet_first_and_last_post</th>\n",
       "      <th>duplicate_cluster</th>\n",
       "      <th>...</th>\n",
       "      <th>total_tweets_after_1_hours</th>\n",
       "      <th>total_tweets_after_2_hours</th>\n",
       "      <th>total_tweets_after_5_hours</th>\n",
       "      <th>total_tweets_after_10_hours</th>\n",
       "      <th>total_tweets_after_15_hours</th>\n",
       "      <th>total_tweets_after_24_hours</th>\n",
       "      <th>total_tweets_after_50_hours</th>\n",
       "      <th>total_tweets_after_120_hours</th>\n",
       "      <th>total_tweets_after_480_hours</th>\n",
       "      <th>month_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31032</td>\n",
       "      <td>politifact11709</td>\n",
       "      <td>1</td>\n",
       "      <td>poli</td>\n",
       "      <td>1180900192</td>\n",
       "      <td>1538510995</td>\n",
       "      <td>03/06/2007</td>\n",
       "      <td>02/10/2018</td>\n",
       "      <td>4139</td>\n",
       "      <td>26025</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2007-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31424</td>\n",
       "      <td>politifact773</td>\n",
       "      <td>1</td>\n",
       "      <td>poli</td>\n",
       "      <td>1185915666</td>\n",
       "      <td>1544929901</td>\n",
       "      <td>31/07/2007</td>\n",
       "      <td>16/12/2018</td>\n",
       "      <td>4156</td>\n",
       "      <td>26391</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31310</td>\n",
       "      <td>politifact150</td>\n",
       "      <td>1</td>\n",
       "      <td>poli</td>\n",
       "      <td>1186670987</td>\n",
       "      <td>1544235921</td>\n",
       "      <td>09/08/2007</td>\n",
       "      <td>08/12/2018</td>\n",
       "      <td>4139</td>\n",
       "      <td>26283</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2007-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31628</td>\n",
       "      <td>politifact86</td>\n",
       "      <td>1</td>\n",
       "      <td>poli</td>\n",
       "      <td>1187924695</td>\n",
       "      <td>1510206606</td>\n",
       "      <td>24/08/2007</td>\n",
       "      <td>09/11/2017</td>\n",
       "      <td>3730</td>\n",
       "      <td>26571</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31444</td>\n",
       "      <td>politifact215</td>\n",
       "      <td>1</td>\n",
       "      <td>poli</td>\n",
       "      <td>1190842571</td>\n",
       "      <td>1544804809</td>\n",
       "      <td>26/09/2007</td>\n",
       "      <td>14/12/2018</td>\n",
       "      <td>4097</td>\n",
       "      <td>26409</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2007-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               id  counter dataset  timestamp_first_tweet  \\\n",
       "0       31032  politifact11709        1    poli             1180900192   \n",
       "1       31424    politifact773        1    poli             1185915666   \n",
       "2       31310    politifact150        1    poli             1186670987   \n",
       "3       31628     politifact86        1    poli             1187924695   \n",
       "4       31444    politifact215        1    poli             1190842571   \n",
       "\n",
       "   timestamp_last_tweet date_first_tweet date_last_tweet  \\\n",
       "0            1538510995       03/06/2007      02/10/2018   \n",
       "1            1544929901       31/07/2007      16/12/2018   \n",
       "2            1544235921       09/08/2007      08/12/2018   \n",
       "3            1510206606       24/08/2007      09/11/2017   \n",
       "4            1544804809       26/09/2007      14/12/2018   \n",
       "\n",
       "   days_betweet_first_and_last_post  duplicate_cluster  ...  \\\n",
       "0                              4139              26025  ...   \n",
       "1                              4156              26391  ...   \n",
       "2                              4139              26283  ...   \n",
       "3                              3730              26571  ...   \n",
       "4                              4097              26409  ...   \n",
       "\n",
       "  total_tweets_after_1_hours  total_tweets_after_2_hours  \\\n",
       "0                          1                           1   \n",
       "1                          1                           1   \n",
       "2                          2                           2   \n",
       "3                          1                           1   \n",
       "4                          2                           2   \n",
       "\n",
       "  total_tweets_after_5_hours  total_tweets_after_10_hours  \\\n",
       "0                          2                            2   \n",
       "1                          1                            1   \n",
       "2                          2                            2   \n",
       "3                          1                            1   \n",
       "4                          2                            2   \n",
       "\n",
       "   total_tweets_after_15_hours  total_tweets_after_24_hours  \\\n",
       "0                            2                            3   \n",
       "1                            1                            1   \n",
       "2                            2                            2   \n",
       "3                            1                            1   \n",
       "4                            2                            2   \n",
       "\n",
       "   total_tweets_after_50_hours  total_tweets_after_120_hours  \\\n",
       "0                            3                             3   \n",
       "1                            1                             1   \n",
       "2                            2                             2   \n",
       "3                            1                             1   \n",
       "4                            3                             4   \n",
       "\n",
       "   total_tweets_after_480_hours  month_year  \n",
       "0                             4     2007-03  \n",
       "1                             1     2007-07  \n",
       "2                             2     2007-09  \n",
       "3                             1     2007-08  \n",
       "4                             4     2007-09  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbmulti = pd.read_csv(r'E:\\social media datasets\\Fbmultilingual.csv')\n",
    "fbmulti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22f4c9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbmulti.tpfc_rating_encoding.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f915f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tpfc_rating_encoding\n",
       "0    17182\n",
       "1     8269\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbmulti.tpfc_rating_encoding.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "803746d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64\n"
     ]
    }
   ],
   "source": [
    "print(fbmulti['timestamp_first_tweet'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c53bb2",
   "metadata": {},
   "source": [
    "# 3. MediaEval15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3fbb4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mediaeval15(folder_path):\n",
    "    # Load tweet data\n",
    "    tweet_cols = ['tweetId', 'tweetText', 'userId', 'imageId', 'username', 'timestamp', 'label']\n",
    "    tweets_dev = pd.read_csv(os.path.join(folder_path, 'tweets_dev.txt'), sep='\\t', names=tweet_cols, header=0)\n",
    "    tweets_test = pd.read_csv(os.path.join(folder_path, 'tweets_test.txt'), sep='\\t', names=tweet_cols, header=0)\n",
    "    tweets = pd.concat([tweets_dev, tweets_test], ignore_index=True)\n",
    "\n",
    "    # Load user features\n",
    "    user_cols = ['tweetId', 'num_friends', 'num_followers', 'folfriend_ratio', 'times_listed', 'has_url', 'is_verified', 'num_tweets']\n",
    "    user_dev = pd.read_csv(os.path.join(folder_path, 'user_features_dev.csv'), skipinitialspace=True)\n",
    "    user_test = pd.read_csv(os.path.join(folder_path, 'user_features_test.txt'), names=user_cols, header=0)\n",
    "    user_features = pd.concat([user_dev, user_test], ignore_index=True)\n",
    "\n",
    "    # Load tweet-level features (e.g. retweets)\n",
    "    tweet_feat_cols = ['tweetId', 'num_words', 'text_length', 'contains_questmark', 'num_questmark',\n",
    "                       'contains_exclammark', 'num_exclammark', 'contains_happyemo', 'contains_sademo',\n",
    "                       'contains_firstorderpron', 'contains_secondorderpron', 'contains_thirdorderpron',\n",
    "                       'num_uppercasechars', 'num_possentiwords', 'num_negsentiwords', 'num_mentions',\n",
    "                       'num_hashtags', 'num_URLs', 'num_retweets']\n",
    "    \n",
    "    tweet_feats_test = pd.read_csv(os.path.join(folder_path, 'tweet_features_test.txt'), names=tweet_feat_cols, header=0)\n",
    "    tweet_feats_dev = pd.read_csv(os.path.join(folder_path, 'tweet_features_dev.csv'), skipinitialspace=True)\n",
    "    tweet_features = pd.concat([tweet_feats_test, tweet_feats_dev], ignore_index=True)\n",
    "\n",
    "    # Merge all\n",
    "    df = tweets.merge(user_features, on='tweetId', how='left')\n",
    "    df = df.merge(tweet_features[['tweetId', 'num_retweets']], on='tweetId', how='left')\n",
    "\n",
    "    # Keep only required columns\n",
    "    final_df = df[['tweetId', 'tweetText', 'timestamp', 'label', 'username',\n",
    "                   'num_followers', 'num_friends', 'is_verified', 'num_retweets']]\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c976e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = r'D:\\text+image\\text+image\\mediaeval2015'\n",
    "mediaeval15 = load_mediaeval15(dataset_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5f225e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetId</th>\n",
       "      <th>tweetText</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>username</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>num_friends</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>num_retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18027</th>\n",
       "      <td>578433150071775232</td>\n",
       "      <td>Un présentateur de la ZDF confesse avoir truqu...</td>\n",
       "      <td>Thu Mar 19 05:49:44 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "      <td>Cdt_Sylvestre</td>\n",
       "      <td>774.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18028</th>\n",
       "      <td>578433646597656576</td>\n",
       "      <td>Oh les kleine menteurs \"@CorineBarella: Un pré...</td>\n",
       "      <td>Thu Mar 19 05:51:42 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "      <td>damomarc</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18029</th>\n",
       "      <td>578486910491996160</td>\n",
       "      <td>Este es el programa de ZDF en el que confirman...</td>\n",
       "      <td>Thu Mar 19 09:23:21 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "      <td>javierpascual</td>\n",
       "      <td>4545.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18030</th>\n",
       "      <td>578505023912591360</td>\n",
       "      <td>11.34 - wir haben FAST Mittag ▶ Riesen Verwirr...</td>\n",
       "      <td>Thu Mar 19 10:35:20 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "      <td>aotto1968_2</td>\n",
       "      <td>4896.0</td>\n",
       "      <td>3498.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18031</th>\n",
       "      <td>578305144380612609</td>\n",
       "      <td>Sorry, @yanisvaroufakis! https://t.co/BSkYrbII...</td>\n",
       "      <td>Wed Mar 18 21:21:05 +0000 2015</td>\n",
       "      <td>fake</td>\n",
       "      <td>janboehm</td>\n",
       "      <td>188561.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tweetId                                          tweetText  \\\n",
       "18027  578433150071775232  Un présentateur de la ZDF confesse avoir truqu...   \n",
       "18028  578433646597656576  Oh les kleine menteurs \"@CorineBarella: Un pré...   \n",
       "18029  578486910491996160  Este es el programa de ZDF en el que confirman...   \n",
       "18030  578505023912591360  11.34 - wir haben FAST Mittag ▶ Riesen Verwirr...   \n",
       "18031  578305144380612609  Sorry, @yanisvaroufakis! https://t.co/BSkYrbII...   \n",
       "\n",
       "                            timestamp label       username  num_followers  \\\n",
       "18027  Thu Mar 19 05:49:44 +0000 2015  fake  Cdt_Sylvestre          774.0   \n",
       "18028  Thu Mar 19 05:51:42 +0000 2015  fake       damomarc         1239.0   \n",
       "18029  Thu Mar 19 09:23:21 +0000 2015  fake  javierpascual         4545.0   \n",
       "18030  Thu Mar 19 10:35:20 +0000 2015  fake    aotto1968_2         4896.0   \n",
       "18031  Wed Mar 18 21:21:05 +0000 2015  fake       janboehm       188561.0   \n",
       "\n",
       "       num_friends is_verified  num_retweets  \n",
       "18027        498.0       False           0.0  \n",
       "18028       1994.0       False           0.0  \n",
       "18029        975.0       False           0.0  \n",
       "18030       3498.0       False           0.0  \n",
       "18031        286.0        True           0.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediaeval15.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e205a994-c4a1-40b6-ba8c-0e9281f19f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweetId', 'tweetText', 'timestamp', 'label', 'username',\n",
       "       'num_followers', 'num_friends', 'is_verified', 'num_retweets'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediaeval15.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0666041b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fake', 'humor', 'real'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediaeval15.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b75c8058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "fake     9288\n",
       "real     6130\n",
       "humor    2614\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mediaeval15.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc7da45",
   "metadata": {},
   "source": [
    "# 4. PHEME-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d67c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b0ee346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pheme5_original(main_folder):\n",
    "    data = []\n",
    "\n",
    "    # Traverse event folders\n",
    "    for event_name in os.listdir(main_folder):\n",
    "        event_path = os.path.join(main_folder, event_name)\n",
    "        if not os.path.isdir(event_path):\n",
    "            continue\n",
    "\n",
    "        for label_type in ['rumours', 'non-rumours']:\n",
    "            label_path = os.path.join(event_path, label_type)\n",
    "            if not os.path.isdir(label_path):\n",
    "                continue\n",
    "\n",
    "            for tweet_folder in os.listdir(label_path):\n",
    "                tweet_dir = os.path.join(label_path, tweet_folder, 'source-tweet')\n",
    "                if not os.path.exists(tweet_dir):\n",
    "                    continue\n",
    "\n",
    "                # Load JSON file in the source-tweet folder\n",
    "                for json_file in glob(os.path.join(tweet_dir, '*.json')):\n",
    "                    try:\n",
    "                        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                            tweet = json.load(f)\n",
    "\n",
    "                        user = tweet.get('user', {})\n",
    "                        data.append({\n",
    "                            'id': tweet.get('id'),\n",
    "                            'text': tweet.get('text'),\n",
    "                            'created_at': tweet.get('created_at'),\n",
    "                            'label': label_type,\n",
    "                            'followers_count': user.get('followers_count'),\n",
    "                            'friends_count': user.get('friends_count'),\n",
    "                            'verified': user.get('verified'),\n",
    "                            'retweet_count': tweet.get('retweet_count'),\n",
    "                            'favorite_count': tweet.get('favorite_count')\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {json_file}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c6350351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>label</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552783238415265792</td>\n",
       "      <td>Breaking: At least 10 dead, 5 injured after tO...</td>\n",
       "      <td>Wed Jan 07 11:06:08 +0000 2015</td>\n",
       "      <td>rumours</td>\n",
       "      <td>1628</td>\n",
       "      <td>246</td>\n",
       "      <td>False</td>\n",
       "      <td>159</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>Wed Jan 07 11:07:51 +0000 2015</td>\n",
       "      <td>rumours</td>\n",
       "      <td>129573</td>\n",
       "      <td>337</td>\n",
       "      <td>True</td>\n",
       "      <td>486</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552783745565347840</td>\n",
       "      <td>Ten killed in shooting at headquarters of Fren...</td>\n",
       "      <td>Wed Jan 07 11:08:09 +0000 2015</td>\n",
       "      <td>rumours</td>\n",
       "      <td>529882</td>\n",
       "      <td>3051</td>\n",
       "      <td>True</td>\n",
       "      <td>127</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552784168849907712</td>\n",
       "      <td>BREAKING: 10 dead in shooting at headquarters ...</td>\n",
       "      <td>Wed Jan 07 11:09:50 +0000 2015</td>\n",
       "      <td>rumours</td>\n",
       "      <td>499741</td>\n",
       "      <td>31</td>\n",
       "      <td>True</td>\n",
       "      <td>105</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552784526955806720</td>\n",
       "      <td>Reuters: 10 people shot dead at headquarters o...</td>\n",
       "      <td>Wed Jan 07 11:11:16 +0000 2015</td>\n",
       "      <td>rumours</td>\n",
       "      <td>1377384</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>412</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  552783238415265792  Breaking: At least 10 dead, 5 injured after tO...   \n",
       "1  552783667052167168  France: 10 people dead after shooting at HQ of...   \n",
       "2  552783745565347840  Ten killed in shooting at headquarters of Fren...   \n",
       "3  552784168849907712  BREAKING: 10 dead in shooting at headquarters ...   \n",
       "4  552784526955806720  Reuters: 10 people shot dead at headquarters o...   \n",
       "\n",
       "                       created_at    label  followers_count  friends_count  \\\n",
       "0  Wed Jan 07 11:06:08 +0000 2015  rumours             1628            246   \n",
       "1  Wed Jan 07 11:07:51 +0000 2015  rumours           129573            337   \n",
       "2  Wed Jan 07 11:08:09 +0000 2015  rumours           529882           3051   \n",
       "3  Wed Jan 07 11:09:50 +0000 2015  rumours           499741             31   \n",
       "4  Wed Jan 07 11:11:16 +0000 2015  rumours          1377384              6   \n",
       "\n",
       "   verified  retweet_count  favorite_count  \n",
       "0     False            159              14  \n",
       "1      True            486              38  \n",
       "2      True            127              15  \n",
       "3      True            105              15  \n",
       "4      True            412              32  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_df = load_pheme5_original(r'D:\\text datasets\\text datasets\\phemernrdataset\\pheme-rnr-dataset')\n",
    "pheme_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19b9b1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rumours', 'non-rumours'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "030735b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "non-rumours    3830\n",
       "rumours        1972\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee2d32d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pheme_reposts(main_folder):\n",
    "    repost_data = []\n",
    "\n",
    "    for event_name in os.listdir(main_folder):\n",
    "        event_path = os.path.join(main_folder, event_name)\n",
    "        if not os.path.isdir(event_path):\n",
    "            continue\n",
    "\n",
    "        for label_type in ['rumours', 'non-rumours']:\n",
    "            label_path = os.path.join(event_path, label_type)\n",
    "            if not os.path.isdir(label_path):\n",
    "                continue\n",
    "\n",
    "            for tweet_folder in os.listdir(label_path):\n",
    "                reactions_dir = os.path.join(label_path, tweet_folder, 'reactions')\n",
    "                if not os.path.exists(reactions_dir):\n",
    "                    continue\n",
    "\n",
    "                for json_file in glob(os.path.join(reactions_dir, '*.json')):\n",
    "                    try:\n",
    "                        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                            tweet = json.load(f)\n",
    "\n",
    "                        original_id = tweet.get('in_reply_to_status_id')\n",
    "                        if original_id is None:\n",
    "                            continue  # skip if it's not a reply\n",
    "\n",
    "                        repost_data.append({\n",
    "                            'id': str(original_id),          # original tweet ID\n",
    "                            'text': tweet.get('text', ''),\n",
    "                            'label': label_type\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {json_file}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(repost_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5083eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552783238415265792</td>\n",
       "      <td>@H_E_Samuel @George_Berridge @michael_taggart ...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552783238415265792</td>\n",
       "      <td>@H_E_Samuel Hi Henry would you be willing to g...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552783238415265792</td>\n",
       "      <td>@H_E_Samuel @H_E_Samuel please call them terro...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552783238415265792</td>\n",
       "      <td>@H_E_Samuel French govt needs to take strict a...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552787794503143424</td>\n",
       "      <td>@EdwardBowden @H_E_Samuel @George_Berridge @mi...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  552783238415265792  @H_E_Samuel @George_Berridge @michael_taggart ...   \n",
       "1  552783238415265792  @H_E_Samuel Hi Henry would you be willing to g...   \n",
       "2  552783238415265792  @H_E_Samuel @H_E_Samuel please call them terro...   \n",
       "3  552783238415265792  @H_E_Samuel French govt needs to take strict a...   \n",
       "4  552787794503143424  @EdwardBowden @H_E_Samuel @George_Berridge @mi...   \n",
       "\n",
       "     label  \n",
       "0  rumours  \n",
       "1  rumours  \n",
       "2  rumours  \n",
       "3  rumours  \n",
       "4  rumours  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_repost = load_pheme_reposts(r'E:\\social media datasets\\pheme5\\pheme-rnr-dataset')\n",
    "pheme_repost.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e400e31",
   "metadata": {},
   "source": [
    "# 5. PHEME-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "846ab451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pheme9(pheme_root):\n",
    "\n",
    "    data = []\n",
    "    threads_root = os.path.join(pheme_root, \"threads\")\n",
    "\n",
    "    for lang in os.listdir(threads_root):  # 'en', 'de'\n",
    "        lang_dir = os.path.join(threads_root, lang)\n",
    "        if not os.path.isdir(lang_dir):\n",
    "            continue\n",
    "\n",
    "        for event in os.listdir(lang_dir):\n",
    "            event_path = os.path.join(lang_dir, event)\n",
    "            if not os.path.isdir(event_path):\n",
    "                continue\n",
    "\n",
    "            for tweet_folder in os.listdir(event_path):\n",
    "                tweet_path = os.path.join(event_path, tweet_folder)\n",
    "                if not os.path.isdir(tweet_path):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    source_tweet_dir = os.path.join(tweet_path, \"source-tweets\")\n",
    "                    annotation_file = os.path.join(tweet_path, \"annotation.json\")\n",
    "\n",
    "                    tweet_files = os.listdir(source_tweet_dir)\n",
    "                    if not tweet_files:\n",
    "                        continue\n",
    "\n",
    "                    tweet_file = os.path.join(source_tweet_dir, tweet_files[0])\n",
    "\n",
    "                    with open(tweet_file, 'r', encoding='utf-8') as f:\n",
    "                        tweet = json.load(f)\n",
    "\n",
    "                    with open(annotation_file, 'r', encoding='utf-8') as f:\n",
    "                        annotation = json.load(f)\n",
    "\n",
    "                    data.append({\n",
    "                        \"id\": tweet.get(\"id_str\", tweet.get(\"id\")),\n",
    "                        \"text\": tweet.get(\"text\"),\n",
    "                        \"created_at\": tweet.get(\"created_at\"),\n",
    "                        \"label\": annotation.get(\"is_rumour\", \"unknown\"),\n",
    "                        \"followers_count\": tweet.get(\"user\", {}).get(\"followers_count\"),\n",
    "                        \"friends_count\": tweet.get(\"user\", {}).get(\"friends_count\"),\n",
    "                        \"verified\": tweet.get(\"user\", {}).get(\"verified\"),\n",
    "                        \"retweet_count\": tweet.get(\"retweet_count\"),\n",
    "                        \"favorite_count\": tweet.get(\"favorite_count\"),\n",
    "                        \"language\": lang\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in {tweet_path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7d6f83b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>label</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>580319406301020160</td>\n",
       "      <td>Flugzeug des Typs A320 ist laut Medienberichte...</td>\n",
       "      <td>Tue Mar 24 10:45:02 +0000 2015</td>\n",
       "      <td>rumour</td>\n",
       "      <td>600503</td>\n",
       "      <td>240</td>\n",
       "      <td>True</td>\n",
       "      <td>87</td>\n",
       "      <td>16</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580321495987146752</td>\n",
       "      <td>Unglück: Germanwings-Airbus stürzt in Südfrank...</td>\n",
       "      <td>Tue Mar 24 10:53:21 +0000 2015</td>\n",
       "      <td>rumour</td>\n",
       "      <td>434364</td>\n",
       "      <td>202</td>\n",
       "      <td>True</td>\n",
       "      <td>234</td>\n",
       "      <td>72</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>580321586391175168</td>\n",
       "      <td>+++EIL+++ In Frankreich ist eine Germanwings-M...</td>\n",
       "      <td>Tue Mar 24 10:53:42 +0000 2015</td>\n",
       "      <td>rumour</td>\n",
       "      <td>102662</td>\n",
       "      <td>4174</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>580323290486611968</td>\n",
       "      <td>Nach dem Absturz der #Germanwings-Maschine kön...</td>\n",
       "      <td>Tue Mar 24 11:00:28 +0000 2015</td>\n",
       "      <td>rumour</td>\n",
       "      <td>670061</td>\n",
       "      <td>263</td>\n",
       "      <td>True</td>\n",
       "      <td>54</td>\n",
       "      <td>15</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>580323743202934785</td>\n",
       "      <td>FULL STORY Germanwings-operated Airbus A320 fl...</td>\n",
       "      <td>Tue Mar 24 11:02:16 +0000 2015</td>\n",
       "      <td>rumour</td>\n",
       "      <td>13605</td>\n",
       "      <td>533</td>\n",
       "      <td>True</td>\n",
       "      <td>83</td>\n",
       "      <td>12</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  580319406301020160  Flugzeug des Typs A320 ist laut Medienberichte...   \n",
       "1  580321495987146752  Unglück: Germanwings-Airbus stürzt in Südfrank...   \n",
       "2  580321586391175168  +++EIL+++ In Frankreich ist eine Germanwings-M...   \n",
       "3  580323290486611968  Nach dem Absturz der #Germanwings-Maschine kön...   \n",
       "4  580323743202934785  FULL STORY Germanwings-operated Airbus A320 fl...   \n",
       "\n",
       "                       created_at   label  followers_count  friends_count  \\\n",
       "0  Tue Mar 24 10:45:02 +0000 2015  rumour           600503            240   \n",
       "1  Tue Mar 24 10:53:21 +0000 2015  rumour           434364            202   \n",
       "2  Tue Mar 24 10:53:42 +0000 2015  rumour           102662           4174   \n",
       "3  Tue Mar 24 11:00:28 +0000 2015  rumour           670061            263   \n",
       "4  Tue Mar 24 11:02:16 +0000 2015  rumour            13605            533   \n",
       "\n",
       "   verified  retweet_count  favorite_count language  \n",
       "0      True             87              16       de  \n",
       "1      True            234              72       de  \n",
       "2      True             26               5       de  \n",
       "3      True             54              15       de  \n",
       "4      True             83              12       de  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme9_df = load_pheme9(r'D:\\text+image\\text+image\\pheme9\\pheme-rumour-scheme-dataset')\n",
    "\n",
    "pheme9_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "562cfa82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rumour'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme9_df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0777779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "rumour    330\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme9_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "103f2e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pheme9_reposts(pheme_root):\n",
    "    data = []\n",
    "    threads_root = os.path.join(pheme_root, \"threads\")\n",
    "\n",
    "    for lang in os.listdir(threads_root):  # 'en', 'de', etc.\n",
    "        lang_dir = os.path.join(threads_root, lang)\n",
    "        if not os.path.isdir(lang_dir):\n",
    "            continue\n",
    "\n",
    "        for event in os.listdir(lang_dir):\n",
    "            event_path = os.path.join(lang_dir, event)\n",
    "            if not os.path.isdir(event_path):\n",
    "                continue\n",
    "\n",
    "            for tweet_folder in os.listdir(event_path):\n",
    "                tweet_path = os.path.join(event_path, tweet_folder)\n",
    "                if not os.path.isdir(tweet_path):\n",
    "                    continue\n",
    "\n",
    "                reactions_dir = os.path.join(tweet_path, \"reactions\")\n",
    "                annotation_file = os.path.join(tweet_path, \"annotation.json\")\n",
    "\n",
    "                try:\n",
    "                    with open(annotation_file, 'r', encoding='utf-8') as f:\n",
    "                        annotation = json.load(f)\n",
    "                    label = annotation.get(\"is_rumour\", \"unknown\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading annotation in {tweet_path}: {e}\")\n",
    "                    label = \"unknown\"\n",
    "\n",
    "                if not os.path.isdir(reactions_dir):\n",
    "                    continue\n",
    "\n",
    "                for file in os.listdir(reactions_dir):\n",
    "                    if not file.endswith('.json'):\n",
    "                        continue\n",
    "\n",
    "                    file_path = os.path.join(reactions_dir, file)\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                            tweet = json.load(f)\n",
    "\n",
    "                        parent_id = tweet.get(\"in_reply_to_status_id\")\n",
    "                        if parent_id is None:\n",
    "                            continue\n",
    "\n",
    "                        data.append({\n",
    "                            \"id\": str(parent_id),  # original tweet ID\n",
    "                            \"text\": tweet.get(\"text\", \"\"),\n",
    "                            \"label\": label,\n",
    "                            \"language\": lang\n",
    "                        })\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ab85e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>580319406301020160</td>\n",
       "      <td>@tagesschau Mein Gott wie grausam!!! Ich hoffe...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>580319406301020160</td>\n",
       "      <td>Unterschiede:\\n\\n@tagesschau und @SZ: Offenbar...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>580319406301020160</td>\n",
       "      <td>@tagesschau ich bin geschockt und kann es nich...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>580319406301020160</td>\n",
       "      <td>@tagesschau  schrecklich ich wünsche allen Ang...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>580321495987146752</td>\n",
       "      <td>An Bord der abgestürzten Maschine befanden sic...</td>\n",
       "      <td>rumour</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  580319406301020160  @tagesschau Mein Gott wie grausam!!! Ich hoffe...   \n",
       "1  580319406301020160  Unterschiede:\\n\\n@tagesschau und @SZ: Offenbar...   \n",
       "2  580319406301020160  @tagesschau ich bin geschockt und kann es nich...   \n",
       "3  580319406301020160  @tagesschau  schrecklich ich wünsche allen Ang...   \n",
       "4  580321495987146752  An Bord der abgestürzten Maschine befanden sic...   \n",
       "\n",
       "    label language  \n",
       "0  rumour       de  \n",
       "1  rumour       de  \n",
       "2  rumour       de  \n",
       "3  rumour       de  \n",
       "4  rumour       de  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme9_repost = load_pheme9_reposts(r'E:\\social media datasets\\pheme9\\pheme-rumour-scheme-dataset')\n",
    "\n",
    "pheme9_repost.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfba956",
   "metadata": {},
   "source": [
    "# 6. PHEME-Veracity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "11f22a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_phemeveracity(main_folder):\n",
    "    data = []\n",
    "\n",
    "    # Traverse event folders\n",
    "    for event_name in os.listdir(main_folder):\n",
    "        event_path = os.path.join(main_folder, event_name)\n",
    "        if not os.path.isdir(event_path):\n",
    "            continue\n",
    "\n",
    "        for label_type in ['rumours', 'non-rumours']:\n",
    "            label_path = os.path.join(event_path, label_type)\n",
    "            if not os.path.isdir(label_path):\n",
    "                continue\n",
    "\n",
    "            for tweet_folder in os.listdir(label_path):\n",
    "                tweet_dir = os.path.join(label_path, tweet_folder, 'source-tweets')\n",
    "                if not os.path.exists(tweet_dir):\n",
    "                    continue\n",
    "\n",
    "                # Load JSON file in the source-tweet folder\n",
    "                for json_file in glob(os.path.join(tweet_dir, '*.json')):\n",
    "                    try:\n",
    "                        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                            tweet = json.load(f)\n",
    "\n",
    "                        user = tweet.get('user', {})\n",
    "                        data.append({\n",
    "                            'id': tweet.get('id'),\n",
    "                            'text': tweet.get('text'),\n",
    "                            'created_at': tweet.get('created_at'),\n",
    "                            'label': label_type,\n",
    "                            'followers_count': user.get('followers_count'),\n",
    "                            'friends_count': user.get('friends_count'),\n",
    "                            'verified': user.get('verified'),\n",
    "                            'retweet_count': tweet.get('retweet_count'),\n",
    "                            'favorite_count': tweet.get('favorite_count')\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {json_file}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7f48bd40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>label</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552783238415265792</td>\n",
       "      <td>Breaking: At least 10 dead, 5 injured after tO...</td>\n",
       "      <td>Wed Jan 07 11:06:08 +0000 2015</td>\n",
       "      <td>rumours</td>\n",
       "      <td>1628</td>\n",
       "      <td>246</td>\n",
       "      <td>False</td>\n",
       "      <td>159</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>Wed Jan 07 11:07:51 +0000 2015</td>\n",
       "      <td>rumours</td>\n",
       "      <td>129573</td>\n",
       "      <td>337</td>\n",
       "      <td>True</td>\n",
       "      <td>486</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552783745565347840</td>\n",
       "      <td>Ten killed in shooting at headquarters of Fren...</td>\n",
       "      <td>Wed Jan 07 11:08:09 +0000 2015</td>\n",
       "      <td>rumours</td>\n",
       "      <td>529882</td>\n",
       "      <td>3051</td>\n",
       "      <td>True</td>\n",
       "      <td>127</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552784168849907712</td>\n",
       "      <td>BREAKING: 10 dead in shooting at headquarters ...</td>\n",
       "      <td>Wed Jan 07 11:09:50 +0000 2015</td>\n",
       "      <td>rumours</td>\n",
       "      <td>499741</td>\n",
       "      <td>31</td>\n",
       "      <td>True</td>\n",
       "      <td>105</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552784526955806720</td>\n",
       "      <td>Reuters: 10 people shot dead at headquarters o...</td>\n",
       "      <td>Wed Jan 07 11:11:16 +0000 2015</td>\n",
       "      <td>rumours</td>\n",
       "      <td>1377384</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>412</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  552783238415265792  Breaking: At least 10 dead, 5 injured after tO...   \n",
       "1  552783667052167168  France: 10 people dead after shooting at HQ of...   \n",
       "2  552783745565347840  Ten killed in shooting at headquarters of Fren...   \n",
       "3  552784168849907712  BREAKING: 10 dead in shooting at headquarters ...   \n",
       "4  552784526955806720  Reuters: 10 people shot dead at headquarters o...   \n",
       "\n",
       "                       created_at    label  followers_count  friends_count  \\\n",
       "0  Wed Jan 07 11:06:08 +0000 2015  rumours             1628            246   \n",
       "1  Wed Jan 07 11:07:51 +0000 2015  rumours           129573            337   \n",
       "2  Wed Jan 07 11:08:09 +0000 2015  rumours           529882           3051   \n",
       "3  Wed Jan 07 11:09:50 +0000 2015  rumours           499741             31   \n",
       "4  Wed Jan 07 11:11:16 +0000 2015  rumours          1377384              6   \n",
       "\n",
       "   verified  retweet_count  favorite_count  \n",
       "0     False            159              14  \n",
       "1      True            486              38  \n",
       "2      True            127              15  \n",
       "3      True            105              15  \n",
       "4      True            412              32  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_ver_df = load_phemeveracity(r'D:\\text datasets\\text datasets\\PHEME_veracity\\all-rnr-annotated-threads')\n",
    "pheme_ver_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "66d6d1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rumours', 'non-rumours'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_ver_df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1912c0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "non-rumours    4023\n",
       "rumours        2402\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_ver_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7d04c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_phemeveracity_reposts(main_folder):\n",
    "    data = []\n",
    "\n",
    "    # Traverse event folders\n",
    "    for event_name in os.listdir(main_folder):\n",
    "        event_path = os.path.join(main_folder, event_name)\n",
    "        if not os.path.isdir(event_path):\n",
    "            continue\n",
    "\n",
    "        for label_type in ['rumours', 'non-rumours']:\n",
    "            label_path = os.path.join(event_path, label_type)\n",
    "            if not os.path.isdir(label_path):\n",
    "                continue\n",
    "\n",
    "            for tweet_folder in os.listdir(label_path):\n",
    "                tweet_dir = os.path.join(label_path, tweet_folder)\n",
    "                reactions_dir = os.path.join(tweet_dir, 'reactions')\n",
    "\n",
    "                if not os.path.exists(reactions_dir):\n",
    "                    continue\n",
    "\n",
    "                for json_file in glob(os.path.join(reactions_dir, '*.json')):\n",
    "                    try:\n",
    "                        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                            tweet = json.load(f)\n",
    "\n",
    "                        parent_id = tweet.get(\"in_reply_to_status_id\")\n",
    "                        if parent_id is None:\n",
    "                            continue\n",
    "\n",
    "                        data.append({\n",
    "                            'id': str(parent_id),  # original tweet ID\n",
    "                            'text': tweet.get('text', ''),\n",
    "                            'label': label_type\n",
    "                        })\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {json_file}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff636a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552783238415265792</td>\n",
       "      <td>@H_E_Samuel @George_Berridge @michael_taggart ...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552783238415265792</td>\n",
       "      <td>@H_E_Samuel Hi Henry would you be willing to g...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552783238415265792</td>\n",
       "      <td>@H_E_Samuel @H_E_Samuel please call them terro...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552783238415265792</td>\n",
       "      <td>@H_E_Samuel French govt needs to take strict a...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552787794503143424</td>\n",
       "      <td>@EdwardBowden @H_E_Samuel @George_Berridge @mi...</td>\n",
       "      <td>rumours</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  552783238415265792  @H_E_Samuel @George_Berridge @michael_taggart ...   \n",
       "1  552783238415265792  @H_E_Samuel Hi Henry would you be willing to g...   \n",
       "2  552783238415265792  @H_E_Samuel @H_E_Samuel please call them terro...   \n",
       "3  552783238415265792  @H_E_Samuel French govt needs to take strict a...   \n",
       "4  552787794503143424  @EdwardBowden @H_E_Samuel @George_Berridge @mi...   \n",
       "\n",
       "     label  \n",
       "0  rumours  \n",
       "1  rumours  \n",
       "2  rumours  \n",
       "3  rumours  \n",
       "4  rumours  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_ver_repost = load_phemeveracity_reposts(r'E:\\social media datasets\\pheme_veracity\\all-rnr-annotated-threads')\n",
    "pheme_ver_repost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "776901f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "non-rumours    67462\n",
       "rumours        30450\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheme_ver_repost.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73154a05-daa6-4419-b5b4-cd972612b6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62d3d927",
   "metadata": {},
   "source": [
    "# 7. RumorEval17\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "688f987a-0198-41f4-b94c-50f52ec2eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rumoureval17_dataset(root_path):\n",
    "    data = []\n",
    "\n",
    "    # Load label mappings from train and dev\n",
    "    label_path = os.path.join(root_path, \"traindev\")\n",
    "    with open(os.path.join(label_path, \"rumoureval-subtaskB-train.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        train_labels = json.load(f)\n",
    "    with open(os.path.join(label_path, \"rumoureval-subtaskB-dev.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        dev_labels = json.load(f)\n",
    "\n",
    "    all_labels = {**train_labels, **dev_labels}  # merge dictionaries\n",
    "\n",
    "    threads_root = os.path.join(root_path, \"rumoureval-data\")\n",
    "\n",
    "    for event in os.listdir(threads_root):\n",
    "        event_path = os.path.join(threads_root, event)\n",
    "        if not os.path.isdir(event_path):\n",
    "            continue\n",
    "\n",
    "        for tweet_folder in os.listdir(event_path):\n",
    "            tweet_path = os.path.join(event_path, tweet_folder)\n",
    "            if not os.path.isdir(tweet_path):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                source_tweet_dir = os.path.join(tweet_path, \"source-tweet\")\n",
    "                tweet_files = os.listdir(source_tweet_dir)\n",
    "                if not tweet_files:\n",
    "                    continue\n",
    "\n",
    "                tweet_file = os.path.join(source_tweet_dir, tweet_files[0])\n",
    "\n",
    "                with open(tweet_file, 'r', encoding='utf-8') as f:\n",
    "                    tweet = json.load(f)\n",
    "\n",
    "                tweet_id = tweet.get(\"id_str\", tweet.get(\"id\"))\n",
    "                label = all_labels.get(tweet_id, \"unknown\")\n",
    "\n",
    "                data.append({\n",
    "                    \"id\": tweet_id,\n",
    "                    \"text\": tweet.get(\"text\"),\n",
    "                    \"created_at\": tweet.get(\"created_at\"),\n",
    "                    \"label\": label,\n",
    "                    \"name\": tweet.get(\"user\", {}).get(\"name\"),\n",
    "                    \"user_followers_count\": tweet.get(\"user\", {}).get(\"followers_count\"),\n",
    "                    \"user_friends_count\": tweet.get(\"user\", {}).get(\"friends_count\"),\n",
    "                    \"user_verified\": tweet.get(\"user\", {}).get(\"verified\"),\n",
    "                    \"retweet_count\": tweet.get(\"retweet_count\"),\n",
    "                    \"favorite_count\": tweet.get(\"favorite_count\")\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in {tweet_path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b96f0b09-521b-41c2-9ed1-1ee902e9c057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>Wed Jan 07 11:07:51 +0000 2015</td>\n",
       "      <td>true</td>\n",
       "      <td>euronews</td>\n",
       "      <td>129573</td>\n",
       "      <td>337</td>\n",
       "      <td>True</td>\n",
       "      <td>486</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552785375161499649</td>\n",
       "      <td>BREAKING: 10 reportedly shot dead at Paris HQ ...</td>\n",
       "      <td>Wed Jan 07 11:14:38 +0000 2015</td>\n",
       "      <td>true</td>\n",
       "      <td>The Independent</td>\n",
       "      <td>972167</td>\n",
       "      <td>1763</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552791196247269378</td>\n",
       "      <td>BREAKING: At least 10 killed in shooting at Fr...</td>\n",
       "      <td>Wed Jan 07 11:37:46 +0000 2015</td>\n",
       "      <td>true</td>\n",
       "      <td>CNN International</td>\n",
       "      <td>3029912</td>\n",
       "      <td>389</td>\n",
       "      <td>True</td>\n",
       "      <td>295</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552791578893619200</td>\n",
       "      <td>Eleven dead in shooting at Paris offices of sa...</td>\n",
       "      <td>Wed Jan 07 11:39:17 +0000 2015</td>\n",
       "      <td>true</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>3091451</td>\n",
       "      <td>1083</td>\n",
       "      <td>True</td>\n",
       "      <td>338</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552792544132997121</td>\n",
       "      <td>BREAKING Charlie Hebdo latest: 11 dead 10 woun...</td>\n",
       "      <td>Wed Jan 07 11:43:07 +0000 2015</td>\n",
       "      <td>true</td>\n",
       "      <td>The Independent</td>\n",
       "      <td>973212</td>\n",
       "      <td>1763</td>\n",
       "      <td>True</td>\n",
       "      <td>203</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  552783667052167168  France: 10 people dead after shooting at HQ of...   \n",
       "1  552785375161499649  BREAKING: 10 reportedly shot dead at Paris HQ ...   \n",
       "2  552791196247269378  BREAKING: At least 10 killed in shooting at Fr...   \n",
       "3  552791578893619200  Eleven dead in shooting at Paris offices of sa...   \n",
       "4  552792544132997121  BREAKING Charlie Hebdo latest: 11 dead 10 woun...   \n",
       "\n",
       "                       created_at label               name  \\\n",
       "0  Wed Jan 07 11:07:51 +0000 2015  true           euronews   \n",
       "1  Wed Jan 07 11:14:38 +0000 2015  true    The Independent   \n",
       "2  Wed Jan 07 11:37:46 +0000 2015  true  CNN International   \n",
       "3  Wed Jan 07 11:39:17 +0000 2015  true       The Guardian   \n",
       "4  Wed Jan 07 11:43:07 +0000 2015  true    The Independent   \n",
       "\n",
       "   user_followers_count  user_friends_count  user_verified  retweet_count  \\\n",
       "0                129573                 337           True            486   \n",
       "1                972167                1763           True            128   \n",
       "2               3029912                 389           True            295   \n",
       "3               3091451                1083           True            338   \n",
       "4                973212                1763           True            203   \n",
       "\n",
       "   favorite_count  \n",
       "0              38  \n",
       "1               5  \n",
       "2              78  \n",
       "3              28  \n",
       "4              32  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumoreval17_df = load_rumoureval17_dataset(r\"D:\\text datasets\\text datasets\\RumorEval17\\semeval2017-task8-dataset\")\n",
    "rumoreval17_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "723c8e9d-3d9d-4a28-b353-8670f1d38c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['true', 'false', 'unverified'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumoreval17_df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "194b69ec-a535-40b8-a88b-5f1fc7387b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "true          137\n",
       "unverified     98\n",
       "false          62\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumoreval17_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c92dd5d-916b-418a-886f-f3e62c7a6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rumoureval17_reposts(root_path):\n",
    "    data = []\n",
    "\n",
    "    # Load label mappings\n",
    "    label_path = os.path.join(root_path, \"traindev\")\n",
    "    with open(os.path.join(label_path, \"rumoureval-subtaskB-train.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        train_labels = json.load(f)\n",
    "    with open(os.path.join(label_path, \"rumoureval-subtaskB-dev.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        dev_labels = json.load(f)\n",
    "\n",
    "    all_labels = {**train_labels, **dev_labels}\n",
    "\n",
    "    threads_root = os.path.join(root_path, \"rumoureval-data\")\n",
    "\n",
    "    for event in os.listdir(threads_root):\n",
    "        event_path = os.path.join(threads_root, event)\n",
    "        if not os.path.isdir(event_path):\n",
    "            continue\n",
    "\n",
    "        for tweet_folder in os.listdir(event_path):\n",
    "            tweet_path = os.path.join(event_path, tweet_folder)\n",
    "            if not os.path.isdir(tweet_path):\n",
    "                continue\n",
    "\n",
    "            reactions_dir = os.path.join(tweet_path, \"replies\")\n",
    "            if not os.path.isdir(reactions_dir):\n",
    "                continue\n",
    "\n",
    "            for file in os.listdir(reactions_dir):\n",
    "                if not file.endswith('.json'):\n",
    "                    continue\n",
    "\n",
    "                file_path = os.path.join(reactions_dir, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        tweet = json.load(f)\n",
    "\n",
    "                    parent_id = tweet.get(\"in_reply_to_status_id\")\n",
    "                    if parent_id is None:\n",
    "                        continue\n",
    "\n",
    "                    label = all_labels.get(str(parent_id), \"unknown\")\n",
    "\n",
    "                    data.append({\n",
    "                        \"id\": str(parent_id),\n",
    "                        \"text\": tweet.get(\"text\", \"\"),\n",
    "                        \"label\": label\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ecb08d3-016b-4c50-a9e2-5e4610bc2980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>MT @euronews France: 10 dead after shooting at...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552785374507175936</td>\n",
       "      <td>@j0nathandavis They who? Stupid and partial op...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552786226546495488</td>\n",
       "      <td>@nanoSpawn Socialists, Antisemites, anti zioni...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>@euronews @TradeDesk_Steve A French crime of p...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>@euronews LOL. 5 million Muslims in France, wh...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  552783667052167168  MT @euronews France: 10 dead after shooting at...   \n",
       "1  552785374507175936  @j0nathandavis They who? Stupid and partial op...   \n",
       "2  552786226546495488  @nanoSpawn Socialists, Antisemites, anti zioni...   \n",
       "3  552783667052167168  @euronews @TradeDesk_Steve A French crime of p...   \n",
       "4  552783667052167168  @euronews LOL. 5 million Muslims in France, wh...   \n",
       "\n",
       "     label  \n",
       "0     true  \n",
       "1  unknown  \n",
       "2  unknown  \n",
       "3     true  \n",
       "4     true  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumoreval19_reposts = load_rumoureval17_reposts(r\"D:\\text datasets\\text datasets\\RumorEval17\\semeval2017-task8-dataset\")\n",
    "rumoreval19_reposts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3bc1004b-de95-425c-9843-69e2f17224ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "unknown       1620\n",
       "true          1173\n",
       "unverified     981\n",
       "false          448\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumoreval19_reposts.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f351067-04f3-4d67-816d-e00ec78c091c",
   "metadata": {},
   "source": [
    "# 8. RumorEval19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0ac797f9-f370-473b-b556-d974c3121ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rumoureval2019_dataset(root_path):\n",
    "    data = []\n",
    "\n",
    "    # Load label mappings\n",
    "    with open(os.path.join(root_path, \"train-key.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        train_labels = json.load(f).get(\"subtaskbenglish\", {})\n",
    "\n",
    "    with open(os.path.join(root_path, \"dev-key.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        dev_labels = json.load(f).get(\"subtaskbenglish\", {})\n",
    "\n",
    "    all_labels = {**train_labels, **dev_labels}\n",
    "\n",
    "    for dataset_folder in [\"reddit-dev-data\", \"reddit-training-data\", \"twitter-english\"]:\n",
    "        dataset_path = os.path.join(root_path, dataset_folder)\n",
    "        if not os.path.isdir(dataset_path):\n",
    "            continue\n",
    "\n",
    "        for event in os.listdir(dataset_path):\n",
    "            event_path = os.path.join(dataset_path, event)\n",
    "            if not os.path.isdir(event_path):\n",
    "                continue\n",
    "\n",
    "            for thread_folder in os.listdir(event_path):\n",
    "                thread_path = os.path.join(event_path, thread_folder)\n",
    "                if not os.path.isdir(thread_path):\n",
    "                    continue\n",
    "\n",
    "                # Only look for the source tweet (not replies or nested paths)\n",
    "                source_tweet_path = os.path.join(thread_path, \"source-tweet\")\n",
    "                if not os.path.isdir(source_tweet_path):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    tweet_files = os.listdir(source_tweet_path)\n",
    "                    if not tweet_files:\n",
    "                        continue\n",
    "\n",
    "                    # There should only be one file in source-tweet folder\n",
    "                    tweet_file = os.path.join(source_tweet_path, tweet_files[0])\n",
    "                    with open(tweet_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                        tweet = json.load(f)\n",
    "\n",
    "                    tweet_id = tweet.get(\"id_str\", tweet.get(\"id\"))\n",
    "                    label = all_labels.get(tweet_id, \"unknown\")\n",
    "\n",
    "                    data.append({\n",
    "                        \"post_id\": tweet_id,\n",
    "                        \"post_text\": tweet.get(\"text\"),\n",
    "                        \"timestamp\": tweet.get(\"created_at\"),\n",
    "                        \"label\": label,\n",
    "                        \"username\": tweet.get(\"user\", {}).get(\"name\"),\n",
    "                        \"num_followers\": tweet.get(\"user\", {}).get(\"followers_count\"),\n",
    "                        \"num_friends\": tweet.get(\"user\", {}).get(\"friends_count\"),\n",
    "                        \"is_verified\": tweet.get(\"user\", {}).get(\"verified\"),\n",
    "                        \"num_retweets\": tweet.get(\"retweet_count\")\n",
    "                    })\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {source_tweet_path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab24d0b1-ac22-4e56-ac8a-ff8d810f652a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>username</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>num_friends</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>num_retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
       "      <td>Wed Jan 07 11:07:51 +0000 2015</td>\n",
       "      <td>true</td>\n",
       "      <td>euronews</td>\n",
       "      <td>129573</td>\n",
       "      <td>337</td>\n",
       "      <td>True</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552785375161499649</td>\n",
       "      <td>BREAKING: 10 reportedly shot dead at Paris HQ ...</td>\n",
       "      <td>Wed Jan 07 11:14:38 +0000 2015</td>\n",
       "      <td>true</td>\n",
       "      <td>The Independent</td>\n",
       "      <td>972167</td>\n",
       "      <td>1763</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552788945017516032</td>\n",
       "      <td>Appalled by the attack on Charlie Hebdo in Par...</td>\n",
       "      <td>Wed Jan 07 11:28:49 +0000 2015</td>\n",
       "      <td>true</td>\n",
       "      <td>Tom Newton Dunn</td>\n",
       "      <td>19332</td>\n",
       "      <td>899</td>\n",
       "      <td>False</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552791196247269378</td>\n",
       "      <td>BREAKING: At least 10 killed in shooting at Fr...</td>\n",
       "      <td>Wed Jan 07 11:37:46 +0000 2015</td>\n",
       "      <td>true</td>\n",
       "      <td>CNN International</td>\n",
       "      <td>3029912</td>\n",
       "      <td>389</td>\n",
       "      <td>True</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552791578893619200</td>\n",
       "      <td>Eleven dead in shooting at Paris offices of sa...</td>\n",
       "      <td>Wed Jan 07 11:39:17 +0000 2015</td>\n",
       "      <td>true</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>3091451</td>\n",
       "      <td>1083</td>\n",
       "      <td>True</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              post_id                                          post_text  \\\n",
       "0  552783667052167168  France: 10 people dead after shooting at HQ of...   \n",
       "1  552785375161499649  BREAKING: 10 reportedly shot dead at Paris HQ ...   \n",
       "2  552788945017516032  Appalled by the attack on Charlie Hebdo in Par...   \n",
       "3  552791196247269378  BREAKING: At least 10 killed in shooting at Fr...   \n",
       "4  552791578893619200  Eleven dead in shooting at Paris offices of sa...   \n",
       "\n",
       "                        timestamp label           username  num_followers  \\\n",
       "0  Wed Jan 07 11:07:51 +0000 2015  true           euronews         129573   \n",
       "1  Wed Jan 07 11:14:38 +0000 2015  true    The Independent         972167   \n",
       "2  Wed Jan 07 11:28:49 +0000 2015  true    Tom Newton Dunn          19332   \n",
       "3  Wed Jan 07 11:37:46 +0000 2015  true  CNN International        3029912   \n",
       "4  Wed Jan 07 11:39:17 +0000 2015  true       The Guardian        3091451   \n",
       "\n",
       "   num_friends  is_verified  num_retweets  \n",
       "0          337         True           486  \n",
       "1         1763         True           128  \n",
       "2          899        False           166  \n",
       "3          389         True           295  \n",
       "4         1083         True           338  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumoreval19_df = load_rumoureval2019_dataset(r\"D:\\text datasets\\text datasets\\rumoureval2019\\rumoureval2019\\rumoureval-2019-training-data\\rumoureval-2019-training-data\")\n",
    "rumoreval19_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d78d7a87-2386-402c-be2d-70fe2488953d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['true', 'false', 'unverified'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumoreval19_df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "926adbc7-1dac-46e0-99e8-6c59cdee3b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "true          145\n",
       "unverified    106\n",
       "false          74\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumoreval19_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0c4d84e-9d86-4723-b17e-91fd201d47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_rumoureval2019_reposts(root_path):\n",
    "    data = []\n",
    "\n",
    "    # Load labels from train and dev keys\n",
    "    with open(os.path.join(root_path, \"train-key.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        train_labels = json.load(f).get(\"subtaskbenglish\", {})\n",
    "\n",
    "    with open(os.path.join(root_path, \"dev-key.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "        dev_labels = json.load(f).get(\"subtaskbenglish\", {})\n",
    "\n",
    "    all_labels = {**train_labels, **dev_labels}\n",
    "\n",
    "    for dataset_folder in [\"reddit-dev-data\", \"reddit-training-data\", \"twitter-english\"]:\n",
    "        dataset_path = os.path.join(root_path, dataset_folder)\n",
    "        if not os.path.isdir(dataset_path):\n",
    "            continue\n",
    "\n",
    "        for event in os.listdir(dataset_path):\n",
    "            event_path = os.path.join(dataset_path, event)\n",
    "            if not os.path.isdir(event_path):\n",
    "                continue\n",
    "\n",
    "            for thread_folder in os.listdir(event_path):\n",
    "                thread_path = os.path.join(event_path, thread_folder)\n",
    "                if not os.path.isdir(thread_path):\n",
    "                    continue\n",
    "\n",
    "                replies_path = os.path.join(thread_path, \"replies\")\n",
    "                if not os.path.isdir(replies_path):\n",
    "                    continue\n",
    "\n",
    "                for reply_file in os.listdir(replies_path):\n",
    "                    if not reply_file.endswith('.json'):\n",
    "                        continue\n",
    "\n",
    "                    reply_path = os.path.join(replies_path, reply_file)\n",
    "                    try:\n",
    "                        with open(reply_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                            tweet = json.load(f)\n",
    "\n",
    "                        parent_id = tweet.get(\"in_reply_to_status_id_str\") or tweet.get(\"in_reply_to_status_id\")\n",
    "                        if parent_id is None:\n",
    "                            continue\n",
    "\n",
    "                        label = all_labels.get(str(parent_id), \"unknown\")\n",
    "\n",
    "                        data.append({\n",
    "                            \"id\": str(parent_id),\n",
    "                            \"text\": tweet.get(\"text\", \"\"),\n",
    "                            \"label\": label\n",
    "                        })\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {reply_path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ea0cb7c-fac5-42ae-8ec2-a677f9ec08fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>MT @euronews France: 10 dead after shooting at...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552785374507175936</td>\n",
       "      <td>@j0nathandavis They who? Stupid and partial op...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552786226546495488</td>\n",
       "      <td>@nanoSpawn Socialists, Antisemites, anti zioni...</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>@euronews @TradeDesk_Steve A French crime of p...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>@euronews LOL. 5 million Muslims in France, wh...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  552783667052167168  MT @euronews France: 10 dead after shooting at...   \n",
       "1  552785374507175936  @j0nathandavis They who? Stupid and partial op...   \n",
       "2  552786226546495488  @nanoSpawn Socialists, Antisemites, anti zioni...   \n",
       "3  552783667052167168  @euronews @TradeDesk_Steve A French crime of p...   \n",
       "4  552783667052167168  @euronews LOL. 5 million Muslims in France, wh...   \n",
       "\n",
       "     label  \n",
       "0     true  \n",
       "1  unknown  \n",
       "2  unknown  \n",
       "3     true  \n",
       "4     true  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumoreval19_repost_df = load_rumoureval2019_reposts(r\"D:\\text datasets\\text datasets\\rumoureval2019\\rumoureval2019\\rumoureval-2019-training-data\\rumoureval-2019-training-data\")\n",
    "rumoreval19_repost_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf1e2ad3-25ca-4eb0-955b-1fc213c65d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['true', 'unknown', 'false', 'unverified'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rumoreval19_repost_df.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46ae153-43ff-40b9-91e1-07320e717304",
   "metadata": {},
   "source": [
    "# 9- Social-Honeypot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "107907a1-eaf0-4b4e-bdfd-9b697c9ad3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tweet_dataset(main_folder):\n",
    "    # File mappings: filename -> label\n",
    "    file_map = {\n",
    "        'content_polluters_tweets.txt': 'polluter',\n",
    "        'legitimate_users_tweets.txt': 'legitimate',\n",
    "        'content_polluters.txt': 'polluter',\n",
    "        'legitimate_users.txt': 'legitimate'\n",
    "    }\n",
    "\n",
    "    # Read user profiles (no headers)\n",
    "    user_profiles = []\n",
    "    for profile_file in ['content_polluters.txt', 'legitimate_users.txt']:\n",
    "        path = os.path.join(main_folder, profile_file)\n",
    "        df = pd.read_csv(path, sep='\\t', header=None,\n",
    "                         names=['UserID', 'ProfileCreatedAt', 'ProfileCollectedAt',\n",
    "                                'NumberOfFollowings', 'NumberOfFollowers', 'NumberOfTweets',\n",
    "                                'ScreenNameLength', 'DescriptionLength'])\n",
    "        df['Label'] = file_map[profile_file]\n",
    "        user_profiles.append(df)\n",
    "    users_df = pd.concat(user_profiles, ignore_index=True)\n",
    "\n",
    "    # Read tweets (no headers)\n",
    "    tweet_data = []\n",
    "    for tweet_file in ['content_polluters_tweets.txt', 'legitimate_users_tweets.txt']:\n",
    "        path = os.path.join(main_folder, tweet_file)\n",
    "        df = pd.read_csv(path, sep='\\t', header=None,\n",
    "                         names=['UserID', 'TweetID', 'TweetText', 'CreatedAt'])\n",
    "        df['Label'] = file_map[tweet_file]\n",
    "        tweet_data.append(df)\n",
    "    tweets_df = pd.concat(tweet_data, ignore_index=True)\n",
    "\n",
    "    # Merge tweets with user profiles on UserID and Label\n",
    "    merged_df = tweets_df.merge(users_df, on=['UserID', 'Label'])\n",
    "\n",
    "    # Select final columns\n",
    "    final_df = merged_df[['TweetID', 'TweetText', 'CreatedAt', 'NumberOfFollowers', 'NumberOfFollowings', 'Label']]\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8dff019-31ba-44dd-bec8-055865440f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetID</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>CreatedAt</th>\n",
       "      <th>NumberOfFollowers</th>\n",
       "      <th>NumberOfFollowings</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5599519501</td>\n",
       "      <td>MELBOURNE ENQUIRY: Seeking a variety of acts f...</td>\n",
       "      <td>2009-11-10 15:14:31</td>\n",
       "      <td>3071</td>\n",
       "      <td>3269</td>\n",
       "      <td>polluter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5600313663</td>\n",
       "      <td>THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...</td>\n",
       "      <td>2009-11-10 15:46:05</td>\n",
       "      <td>3071</td>\n",
       "      <td>3269</td>\n",
       "      <td>polluter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5600328557</td>\n",
       "      <td>THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...</td>\n",
       "      <td>2009-11-10 15:46:40</td>\n",
       "      <td>3071</td>\n",
       "      <td>3269</td>\n",
       "      <td>polluter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5600338093</td>\n",
       "      <td>THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...</td>\n",
       "      <td>2009-11-10 15:47:03</td>\n",
       "      <td>3071</td>\n",
       "      <td>3269</td>\n",
       "      <td>polluter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5600564863</td>\n",
       "      <td>Come to \"The Burlesque Bootcamp - Sydney\" Satu...</td>\n",
       "      <td>2009-11-10 15:56:03</td>\n",
       "      <td>3071</td>\n",
       "      <td>3269</td>\n",
       "      <td>polluter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TweetID                                          TweetText  \\\n",
       "0  5599519501  MELBOURNE ENQUIRY: Seeking a variety of acts f...   \n",
       "1  5600313663  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
       "2  5600328557  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
       "3  5600338093  THE BURLESQUE BOOTCAMP SYDNEY - Open Date tick...   \n",
       "4  5600564863  Come to \"The Burlesque Bootcamp - Sydney\" Satu...   \n",
       "\n",
       "             CreatedAt  NumberOfFollowers  NumberOfFollowings     Label  \n",
       "0  2009-11-10 15:14:31               3071                3269  polluter  \n",
       "1  2009-11-10 15:46:05               3071                3269  polluter  \n",
       "2  2009-11-10 15:46:40               3071                3269  polluter  \n",
       "3  2009-11-10 15:47:03               3071                3269  polluter  \n",
       "4  2009-11-10 15:56:03               3071                3269  polluter  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_folder = r\"D:\\text datasets\\text datasets\\Social-Honeypot\\social_honeypot_icwsm_2011\"\n",
    "socialhoneypot = load_tweet_dataset(main_folder)\n",
    "socialhoneypot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5afaa5b4-306a-45a8-b497-b70be4e0e612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "legitimate    3246377\n",
       "polluter      2333691\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "socialhoneypot.Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14425ea-1602-4f20-bcc6-22b2a9686d41",
   "metadata": {},
   "source": [
    "# 10. Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b9e196-9f12-498c-a258-ce7a281ee2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_twitter(folder_path):\n",
    "    # Define columns for each file\n",
    "    post_cols_dev = ['post_id', 'post_text', 'user_id', 'image_id', 'username', 'timestamp', 'label']\n",
    "    post_cols_test = ['post_id', 'post_text', 'user_id', 'username', 'image_id', 'timestamp']\n",
    "\n",
    "    user_cols = ['post_id', 'num_friends', 'num_followers', 'folfriend_ratio', 'times_listed', 'has_url', 'is_verified', 'num_posts']\n",
    "    post_feat_cols = ['post_id', 'num_words', 'text_length', 'contains_questmark', 'num_questmark',\n",
    "                      'contains_exclammark', 'num_exclammark', 'contains_happyemo', 'contains_sademo',\n",
    "                      'contains_firstorderpron', 'contains_secondorderpron', 'contains_thirdorderpron',\n",
    "                      'num_uppercasechars', 'num_possentiwords', 'num_negsentiwords', 'num_mentions',\n",
    "                      'num_hashtags', 'num_URLs', 'num_retweets']\n",
    "\n",
    "    # Load dev set\n",
    "    dev_path = os.path.join(folder_path, 'devset')\n",
    "    posts_dev = pd.read_csv(os.path.join(dev_path, 'posts.txt'), sep='\\t', names=post_cols_dev, header=0)\n",
    "    users_dev = pd.read_csv(os.path.join(dev_path, 'user_features.txt'), sep=',', names=user_cols, header=0)\n",
    "    feats_dev = pd.read_csv(os.path.join(dev_path, 'post_features.txt'), sep=',', names=post_feat_cols, header=0)\n",
    "\n",
    "    # Merge dev\n",
    "    dev = posts_dev.merge(users_dev, on='post_id', how='left')\n",
    "    dev = dev.merge(feats_dev[['post_id', 'num_retweets']], on='post_id', how='left')\n",
    "\n",
    "    # Load test set\n",
    "    test_path = os.path.join(folder_path, 'testset')\n",
    "    posts_test = pd.read_csv(os.path.join(test_path, 'posts.txt'), sep='\\t', names=post_cols_test, header=0)\n",
    "    posts_test[\"label\"] = None  # No label in test set\n",
    "\n",
    "    users_test = pd.read_csv(os.path.join(test_path, 'user_features.txt'), sep=',', names=user_cols, header=0)\n",
    "    feats_test = pd.read_csv(os.path.join(test_path, 'post_features.txt'), sep=',', names=post_feat_cols, header=0)\n",
    "\n",
    "    # Merge test\n",
    "    test = posts_test.merge(users_test, on='post_id', how='left')\n",
    "    test = test.merge(feats_test[['post_id', 'num_retweets']], on='post_id', how='left')\n",
    "\n",
    "    # Concatenate dev and test\n",
    "    df = pd.concat([dev, test], ignore_index=True)\n",
    "\n",
    "    # Select only needed columns\n",
    "    final_df = df[['post_id', 'post_text', 'timestamp', 'label', 'username',\n",
    "                   'num_followers', 'num_friends', 'is_verified', 'num_retweets']]\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb9eba2f-f8a5-440b-9300-4d7d3d744b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>username</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>num_friends</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>num_retweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>324597532548276224</td>\n",
       "      <td>Don't need feds to solve the #bostonbombing wh...</td>\n",
       "      <td>Wed Apr 17 18:57:37 +0000 2013</td>\n",
       "      <td>fake</td>\n",
       "      <td>SantaCruzShred</td>\n",
       "      <td>634</td>\n",
       "      <td>1445</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>325145334739267584</td>\n",
       "      <td>PIC: Comparison of #Boston suspect Sunil Tripa...</td>\n",
       "      <td>Fri Apr 19 07:14:23 +0000 2013</td>\n",
       "      <td>fake</td>\n",
       "      <td>Oscar_Wang</td>\n",
       "      <td>271</td>\n",
       "      <td>565</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>325152091423248385</td>\n",
       "      <td>I'm not completely convinced that it's this Su...</td>\n",
       "      <td>Fri Apr 19 07:41:14 +0000 2013</td>\n",
       "      <td>fake</td>\n",
       "      <td>jamwil</td>\n",
       "      <td>649</td>\n",
       "      <td>576</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324554646976868352</td>\n",
       "      <td>Brutal lo que se puede conseguir en colaboraci...</td>\n",
       "      <td>Wed Apr 17 16:07:12 +0000 2013</td>\n",
       "      <td>fake</td>\n",
       "      <td>rubenson80</td>\n",
       "      <td>297</td>\n",
       "      <td>546</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>324315545572896768</td>\n",
       "      <td>4chan and the bombing. just throwing it out th...</td>\n",
       "      <td>Wed Apr 17 00:17:06 +0000 2013</td>\n",
       "      <td>fake</td>\n",
       "      <td>Slimlenny</td>\n",
       "      <td>60</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              post_id                                          post_text  \\\n",
       "0  324597532548276224  Don't need feds to solve the #bostonbombing wh...   \n",
       "1  325145334739267584  PIC: Comparison of #Boston suspect Sunil Tripa...   \n",
       "2  325152091423248385  I'm not completely convinced that it's this Su...   \n",
       "3  324554646976868352  Brutal lo que se puede conseguir en colaboraci...   \n",
       "4  324315545572896768  4chan and the bombing. just throwing it out th...   \n",
       "\n",
       "                        timestamp label        username  num_followers  \\\n",
       "0  Wed Apr 17 18:57:37 +0000 2013  fake  SantaCruzShred            634   \n",
       "1  Fri Apr 19 07:14:23 +0000 2013  fake      Oscar_Wang            271   \n",
       "2  Fri Apr 19 07:41:14 +0000 2013  fake          jamwil            649   \n",
       "3  Wed Apr 17 16:07:12 +0000 2013  fake      rubenson80            297   \n",
       "4  Wed Apr 17 00:17:06 +0000 2013  fake       Slimlenny             60   \n",
       "\n",
       "   num_friends  is_verified  num_retweets  \n",
       "0         1445        False           0.0  \n",
       "1          565        False           0.0  \n",
       "2          576        False           0.0  \n",
       "3          546        False           0.0  \n",
       "4           61        False           0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = load_twitter(r'D:\\text+image\\text+image\\twitter')\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cc00178-194b-4cc2-9df4-28b76ed0b8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "fake    9404\n",
       "real    6226\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "893db3fe-7d3b-4549-b74f-d585ed24f3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fake', 'real', None], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0657fe-0745-4d67-8e91-eecb5fb88269",
   "metadata": {},
   "source": [
    "# 11. Weibo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94fc945d-b420-46e7-960d-58b58124a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weibo_dataset(folder_path):\n",
    "    # Files that include rumor/nonrumor data\n",
    "    label_files = {\n",
    "        'train_rumor.txt': 'rumor',\n",
    "        'train_nonrumor.txt': 'nonrumor',\n",
    "        'test_rumor.txt': 'rumor',\n",
    "        'test_nonrumor.txt': 'nonrumor'\n",
    "    }\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for file_name, label in label_files.items():\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Warning: {file_name} not found in {folder_path}\")\n",
    "            continue\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for i in range(0, len(lines), 3):\n",
    "            if i + 2 >= len(lines):\n",
    "                continue  # Skip incomplete entries\n",
    "\n",
    "            meta = lines[i].strip().split('|')\n",
    "            tweet_text = lines[i + 2].strip()\n",
    "\n",
    "            if len(meta) < 15:  # Basic sanity check\n",
    "                continue\n",
    "\n",
    "            all_data.append({\n",
    "                'tweet_id': meta[0],\n",
    "                'user_name': meta[1],\n",
    "                'publish_time': meta[4],\n",
    "                'user_auth_type': meta[10],\n",
    "                'user_fans_count': meta[11],\n",
    "                'user_follow_count': meta[12],\n",
    "                'retweet_count': meta[6],\n",
    "                'praise_count': meta[8],\n",
    "                'tweet_content': tweet_text,\n",
    "                'label': label\n",
    "            })\n",
    "\n",
    "    # Create base DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Convert appropriate columns to numeric\n",
    "    numeric_cols = ['user_fans_count', 'user_follow_count', 'retweet_count', 'praise_count']\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cacbc7d-5c53-478b-afd7-caccea85c3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>user_auth_type</th>\n",
       "      <th>user_fans_count</th>\n",
       "      <th>user_follow_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>praise_count</th>\n",
       "      <th>tweet_content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3511947309647762</td>\n",
       "      <td>地球超级爆料</td>\n",
       "      <td>2012-11-13 16:55</td>\n",
       "      <td>0</td>\n",
       "      <td>5047.0</td>\n",
       "      <td>1770.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>震惊，转发求证：【想都不敢想 ，在美国一桶金龙鱼食用油只要8元人民币】 一桶食用油相当于中国...</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3576100079039606</td>\n",
       "      <td>Noodles_Liu</td>\n",
       "      <td>2013-05-09 17:36</td>\n",
       "      <td>0</td>\n",
       "      <td>9049.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>【法院无底线】湖南长沙一位小朋友上学路上捡到3万元，原地不动等失主，结果被人冒领。不知情的孩...</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3899073935617462</td>\n",
       "      <td>淡然一夏02</td>\n",
       "      <td>2015-10-17 23:18</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>转发:我校需要小孩的衣服,新旧不限!西藏阿里地区是世界海拔最高的地区请问周围有没有四到十岁孩...</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3584521306131914</td>\n",
       "      <td>凤凰吴氏制茶</td>\n",
       "      <td>2013-06-01 23:19</td>\n",
       "      <td>0</td>\n",
       "      <td>3362.0</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>立刻检查一下你家里的牙膏，如果是黑色条马上扔掉！ 大家买膏请留心,买牙膏时注意牙膏管反面 底...</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3553661986467439</td>\n",
       "      <td>咩咩百分百</td>\n",
       "      <td>2013-03-08 19:35</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>快快转发，急急急！中央电视台《焦点访谈》已经播出，可口可乐承认旗下(果粒橙)含有美国禁用农药...</td>\n",
       "      <td>rumor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tweet_id    user_name      publish_time user_auth_type  \\\n",
       "0  3511947309647762       地球超级爆料  2012-11-13 16:55              0   \n",
       "1  3576100079039606  Noodles_Liu  2013-05-09 17:36              0   \n",
       "2  3899073935617462       淡然一夏02  2015-10-17 23:18              0   \n",
       "3  3584521306131914       凤凰吴氏制茶  2013-06-01 23:19              0   \n",
       "4  3553661986467439        咩咩百分百  2013-03-08 19:35              0   \n",
       "\n",
       "   user_fans_count  user_follow_count  retweet_count  praise_count  \\\n",
       "0           5047.0             1770.0             79             0   \n",
       "1           9049.0              490.0              1             0   \n",
       "2              8.0               82.0              0             0   \n",
       "3           3362.0             1908.0              5             0   \n",
       "4             32.0               20.0              0             0   \n",
       "\n",
       "                                       tweet_content  label  \n",
       "0  震惊，转发求证：【想都不敢想 ，在美国一桶金龙鱼食用油只要8元人民币】 一桶食用油相当于中国...  rumor  \n",
       "1  【法院无底线】湖南长沙一位小朋友上学路上捡到3万元，原地不动等失主，结果被人冒领。不知情的孩...  rumor  \n",
       "2  转发:我校需要小孩的衣服,新旧不限!西藏阿里地区是世界海拔最高的地区请问周围有没有四到十岁孩...  rumor  \n",
       "3  立刻检查一下你家里的牙膏，如果是黑色条马上扔掉！ 大家买膏请留心,买牙膏时注意牙膏管反面 底...  rumor  \n",
       "4  快快转发，急急急！中央电视台《焦点访谈》已经播出，可口可乐承认旗下(果粒橙)含有美国禁用农药...  rumor  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weibo_df = load_weibo_dataset(r'D:\\text+image\\text+image\\Weibo-dataset-main\\Weibo-dataset-main')\n",
    "weibo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827e2c41-1fb8-47c6-bf1d-92352b736c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(weibo_df['user_auth_type'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc3bec2-aa0e-4344-b9cb-4c1c1f76523c",
   "metadata": {},
   "source": [
    "# 12. Weibo-Rumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1df088d6-fa62-4796-94bf-bdf0b8a06e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weibo_rumor_dataset(root_path):\n",
    "    data = []\n",
    "\n",
    "    txt_path = os.path.join(root_path, \"Weibo.txt\")\n",
    "    json_dir = os.path.join(root_path, \"Weibo\")\n",
    "\n",
    "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "\n",
    "            event_id_part = parts[0]  # e.g., \"eid:10031080900\"\n",
    "            label_part = parts[1]     # e.g., \"label:0\"\n",
    "\n",
    "            event_id = event_id_part.replace(\"eid:\", \"\")\n",
    "            label = int(label_part.replace(\"label:\", \"\"))\n",
    "\n",
    "            json_path = os.path.join(json_dir, f\"{event_id}.json\")\n",
    "            if not os.path.isfile(json_path):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with open(json_path, 'r', encoding='utf-8') as jf:\n",
    "                    posts = json.load(jf)\n",
    "\n",
    "                # Find the post where id == event_id\n",
    "                root_post = next((post for post in posts if str(post.get(\"id\")) == event_id), None)\n",
    "                if not root_post:\n",
    "                    continue\n",
    "\n",
    "                data.append({\n",
    "                    \"id\": root_post.get(\"id\"),\n",
    "                    \"original_text\": root_post.get(\"original_text\", \"\"),\n",
    "                    \"username\": root_post.get(\"username\", \"\"),\n",
    "                    \"followers_count\": root_post.get(\"followers_count\", 0),\n",
    "                    \"friends_count\": root_post.get(\"friends_count\", 0),\n",
    "                    \"verified\": root_post.get(\"verified\", False),\n",
    "                    \"reposts_count\": root_post.get(\"reposts_count\", 0),\n",
    "                    \"favourites_count\": root_post.get(\"favourites_count\", 0),\n",
    "                    \"label\": label\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {json_path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8556a705-09a7-4235-8e47-dafd252c9a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>username</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>reposts_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10031080900</td>\n",
       "      <td>毛新宇 深情演唱新作《献给爷爷奶奶的歌》 http://t.cn/h1R0Rj</td>\n",
       "      <td>历史震惊你</td>\n",
       "      <td>1011418</td>\n",
       "      <td>1273</td>\n",
       "      <td>False</td>\n",
       "      <td>267</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10031994215</td>\n",
       "      <td>如果没有人相信你，那就自己相信自己；如果没人欣赏你，那就自己欣赏自己；如果没人祝福你，那就自...</td>\n",
       "      <td>微博经典语录</td>\n",
       "      <td>3591890</td>\n",
       "      <td>250</td>\n",
       "      <td>False</td>\n",
       "      <td>1624</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10276391917</td>\n",
       "      <td>看了新闻感慨：大运会火炬，怎么跟烤土豆片儿似的，中间还有彩椒和洋葱 ~</td>\n",
       "      <td>全球热门收集</td>\n",
       "      <td>10936954</td>\n",
       "      <td>925</td>\n",
       "      <td>False</td>\n",
       "      <td>546</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10313557537</td>\n",
       "      <td>浮躁风气较盛的今天，并不是没有认真做事的人。但是，“认真”的利益选择性和目的导向性，使很多表...</td>\n",
       "      <td>李纲</td>\n",
       "      <td>131460</td>\n",
       "      <td>199</td>\n",
       "      <td>True</td>\n",
       "      <td>402</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10402071863</td>\n",
       "      <td>[心] 女孩身上某个器官，爸爸碰两次，男朋友碰一次，老公一次都不能碰。大家猜猜是答案是什么~~</td>\n",
       "      <td>重口味腐女营</td>\n",
       "      <td>1212152</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1453</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                      original_text username  \\\n",
       "0  10031080900            毛新宇 深情演唱新作《献给爷爷奶奶的歌》 http://t.cn/h1R0Rj    历史震惊你   \n",
       "1  10031994215  如果没有人相信你，那就自己相信自己；如果没人欣赏你，那就自己欣赏自己；如果没人祝福你，那就自...   微博经典语录   \n",
       "2  10276391917                看了新闻感慨：大运会火炬，怎么跟烤土豆片儿似的，中间还有彩椒和洋葱 ~   全球热门收集   \n",
       "3  10313557537  浮躁风气较盛的今天，并不是没有认真做事的人。但是，“认真”的利益选择性和目的导向性，使很多表...       李纲   \n",
       "4  10402071863    [心] 女孩身上某个器官，爸爸碰两次，男朋友碰一次，老公一次都不能碰。大家猜猜是答案是什么~~   重口味腐女营   \n",
       "\n",
       "   followers_count  friends_count  verified  reposts_count  favourites_count  \\\n",
       "0          1011418           1273     False            267                 6   \n",
       "1          3591890            250     False           1624                 1   \n",
       "2         10936954            925     False            546                48   \n",
       "3           131460            199      True            402               162   \n",
       "4          1212152              0     False           1453                13   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weibo_rumor_df = load_weibo_rumor_dataset(r\"D:\\text datasets\\text datasets\\weibo rumor\")\n",
    "weibo_rumor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de941482-6caa-4bc6-932b-058a31e7d6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weibo_rumor_df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3d6a482-4112-492d-96b2-18b5f9b18489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2351\n",
       "1    2313\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weibo_rumor_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2eff7f08-a18b-43ba-b882-56314e586aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weibo_rumor_reposts(root_path):\n",
    "    data = []\n",
    "\n",
    "    txt_path = os.path.join(root_path, \"Weibo.txt\")\n",
    "    json_dir = os.path.join(root_path, \"Weibo\")\n",
    "\n",
    "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "\n",
    "            event_id_part = parts[0]  # e.g., \"eid:4010312877\"\n",
    "            label_part = parts[1]     # e.g., \"label:0\"\n",
    "            event_id = event_id_part.replace(\"eid:\", \"\")\n",
    "            label = int(label_part.replace(\"label:\", \"\"))\n",
    "\n",
    "            json_path = os.path.join(json_dir, f\"{event_id}.json\")\n",
    "            if not os.path.isfile(json_path):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with open(json_path, 'r', encoding='utf-8') as jf:\n",
    "                    posts = json.load(jf)\n",
    "\n",
    "                for post in posts:\n",
    "                    # Skip the root post (id == event_id)\n",
    "                    if str(post.get(\"id\")) == event_id:\n",
    "                        continue\n",
    "\n",
    "                    data.append({\n",
    "                        \"id\": post.get(\"id\"),\n",
    "                        \"text\": post.get(\"text\", \"\"),\n",
    "                        \"label\": label\n",
    "                    })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {json_path}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e8c7542-621e-432b-8f83-e88c6c175bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10031139424</td>\n",
       "      <td>我工作，大家先看个乐儿吧，看我有感觉的请自觉汇报感受。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10031149936</td>\n",
       "      <td>[汗]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10031160544</td>\n",
       "      <td>笑而不语。。。。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10031160846</td>\n",
       "      <td>在我看来，力推毛新宇，就是打压太子党的一种温柔方式。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10031161682</td>\n",
       "      <td>转发微博。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                         text  label\n",
       "0  10031139424  我工作，大家先看个乐儿吧，看我有感觉的请自觉汇报感受。      0\n",
       "1  10031149936                          [汗]      0\n",
       "2  10031160544                     笑而不语。。。。      0\n",
       "3  10031160846   在我看来，力推毛新宇，就是打压太子党的一种温柔方式。      0\n",
       "4  10031161682                        转发微博。      0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weibo_reposts_df = load_weibo_rumor_reposts(r\"D:\\text datasets\\text datasets\\weibo rumor\")\n",
    "weibo_reposts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5819e329-68da-44ae-b1c7-3ff32240c889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    2088430\n",
       "0    1712562\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weibo_reposts_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a1f95f",
   "metadata": {},
   "source": [
    "# Read Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "73140be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>username</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>repost_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>language</th>\n",
       "      <th>domain</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>552783667052167168</td>\n",
       "      <td>france 10 people dead after shooting at hq of ...</td>\n",
       "      <td>2015-01-07 11:07:51+00:00</td>\n",
       "      <td>real</td>\n",
       "      <td>euronews</td>\n",
       "      <td>129573.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>True</td>\n",
       "      <td>486</td>\n",
       "      <td>38</td>\n",
       "      <td>en</td>\n",
       "      <td>others</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>552785375161499649</td>\n",
       "      <td>breaking 10 reportedly shot dead at paris hq o...</td>\n",
       "      <td>2015-01-07 11:14:38+00:00</td>\n",
       "      <td>real</td>\n",
       "      <td>The Independent</td>\n",
       "      <td>972167.0</td>\n",
       "      <td>1763.0</td>\n",
       "      <td>True</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>others</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552791196247269378</td>\n",
       "      <td>breaking at least 10 killed in shooting at fre...</td>\n",
       "      <td>2015-01-07 11:37:46+00:00</td>\n",
       "      <td>real</td>\n",
       "      <td>CNN International</td>\n",
       "      <td>3029912.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>True</td>\n",
       "      <td>295</td>\n",
       "      <td>78</td>\n",
       "      <td>en</td>\n",
       "      <td>others</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>552791578893619200</td>\n",
       "      <td>eleven dead in shooting at paris offices of sa...</td>\n",
       "      <td>2015-01-07 11:39:17+00:00</td>\n",
       "      <td>real</td>\n",
       "      <td>The Guardian</td>\n",
       "      <td>3091451.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>True</td>\n",
       "      <td>338</td>\n",
       "      <td>28</td>\n",
       "      <td>en</td>\n",
       "      <td>others</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552792544132997121</td>\n",
       "      <td>breaking charlie hebdo latest 11 dead 10 wound...</td>\n",
       "      <td>2015-01-07 11:43:07+00:00</td>\n",
       "      <td>real</td>\n",
       "      <td>The Independent</td>\n",
       "      <td>973212.0</td>\n",
       "      <td>1763.0</td>\n",
       "      <td>True</td>\n",
       "      <td>203</td>\n",
       "      <td>32</td>\n",
       "      <td>en</td>\n",
       "      <td>others</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              post_id                                               text  \\\n",
       "0  552783667052167168  france 10 people dead after shooting at hq of ...   \n",
       "1  552785375161499649  breaking 10 reportedly shot dead at paris hq o...   \n",
       "2  552791196247269378  breaking at least 10 killed in shooting at fre...   \n",
       "3  552791578893619200  eleven dead in shooting at paris offices of sa...   \n",
       "4  552792544132997121  breaking charlie hebdo latest 11 dead 10 wound...   \n",
       "\n",
       "                  timestamp label           username  follower_count  \\\n",
       "0 2015-01-07 11:07:51+00:00  real           euronews        129573.0   \n",
       "1 2015-01-07 11:14:38+00:00  real    The Independent        972167.0   \n",
       "2 2015-01-07 11:37:46+00:00  real  CNN International       3029912.0   \n",
       "3 2015-01-07 11:39:17+00:00  real       The Guardian       3091451.0   \n",
       "4 2015-01-07 11:43:07+00:00  real    The Independent        973212.0   \n",
       "\n",
       "   friends_count  is_verified  repost_count  likes language  domain platform  \n",
       "0          337.0         True           486     38       en  others  Twitter  \n",
       "1         1763.0         True           128      5       en  others  Twitter  \n",
       "2          389.0         True           295     78       en  others  Twitter  \n",
       "3         1083.0         True           338     28       en  others  Twitter  \n",
       "4         1763.0         True           203     32       en  others  Twitter  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r'D:\\Social-media-dataset-merger\\keeup-social-media-datasets-merger\\processed_data\\all_originals.parquet'\n",
    "\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96567ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
